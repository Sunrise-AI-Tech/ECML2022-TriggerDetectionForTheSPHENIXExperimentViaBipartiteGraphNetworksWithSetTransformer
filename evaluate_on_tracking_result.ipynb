{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0cf1ce05333a38a1c7d20963072c91b6f8c53f8b73b8785fedacf193384e77026",
   "display_name": "Python 3.8.5 64-bit ('pytorch-cuda': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.stats import mode\n",
    "\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "from main_script.utils import load_config\n",
    "from main_script.utils import load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '/home/tingting/trigger_detection/results/noise_weight/config.pkl'\n",
    "config = pickle.load(open(config_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/tingting/trigger_pred/models/encoders.py:71: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n  m.weight.data = init.xavier_uniform(m.weight.data, gain=nn.init.calculate_gain('relu'))\n/home/tingting/trigger_pred/models/encoders.py:73: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n  m.bias.data = init.constant(m.bias.data, 0.0)\n/home/tingting/trigger_pred/models/encoders.py:280: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n  m.weight.data = init.xavier_uniform(m.weight.data, gain=nn.init.calculate_gain('relu'))\n/home/tingting/trigger_pred/models/encoders.py:282: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n  m.bias.data = init.constant(m.bias.data, 0.0)\n"
     ]
    }
   ],
   "source": [
    "if config['model_name'] == 'GNN_ip':\n",
    "    from models.ip_GNN import IpGNN\n",
    "    model = IpGNN(**config['model'])\n",
    "if config['model_name'] == 'GNN_vp':\n",
    "    from models.vp_GNN import VpGNN\n",
    "    model = VpGNN(**config['model'])\n",
    "if config['model_name'] == 'GNN_Diffpool' or config['model_name'] == 'GNN_Diffpool_trackinfo':\n",
    "    from models.GNN_diffpool import GNNDiffpool\n",
    "    model = GNNDiffpool(**config['model'])\n",
    "if config['model_name'] == 'GNNPairDiffpool' or config['model_name'] == 'GNNPairDiffpool_affinityloss':\n",
    "    from models.GNN_pair_diffpool import GNNPairDiffpool\n",
    "    model = GNNPairDiffpool(**config['model'])\n",
    "if config['model_name'] == 'Diffpool':\n",
    "    from models.Diffpool import Diffpool\n",
    "    model = Diffpool(**config['model'])\n",
    "if config['model_name'] == 'Dense_GNN_Diffpool':\n",
    "    from models.DenseGNNDiffpool import DenseGNNDiffpool\n",
    "    model = DenseGNNDiffpool(**config['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/tingting/trigger_detection/results/noise_weight/checkpoints/model_checkpoint_198.pth.tar\nSuccessfully reloaded!\n"
     ]
    }
   ],
   "source": [
    "result_dir = '/home/tingting/trigger_detection/results/noise_weight'\n",
    "checkpoint_dir = os.path.join(result_dir, 'checkpoints')\n",
    "checkpoint_file = sorted([os.path.join(checkpoint_dir, f) for f in os.listdir(checkpoint_dir) if f.startswith('model_checkpoint')])\n",
    "# checkpoint_file = checkpoint_file[207]\n",
    "# checkpoint_file = checkpoint_file[330]\n",
    "checkpoint_file = checkpoint_file[197]\n",
    "print(checkpoint_file)\n",
    "model = load_checkpoint(checkpoint_file, model)\n",
    "print('Successfully reloaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded 40000 inference samples\n"
     ]
    }
   ],
   "source": [
    "# Test Settings\n",
    "#test_dir1 = os.path.expandvars('physics_data/nontrigger_event/NN')\n",
    "test_dir1 = '/home/tingting/tracking/tracking_result_with_noise_In'\n",
    "test_dir2 = '/home/tingting/tracking/tracking_result_with_noise_D0'\n",
    "#test_dir1 = os.path.expandvars('physics_data/trigger_event')\n",
    "test_samples = 20000\n",
    "batch_size = 1\n",
    "\n",
    "# Load testing data\n",
    "from dataloaders.dataloader_for_tracking_result import HitGraphDataset\n",
    "from dataloaders.dataloader_for_tracking_result import JetsBatchSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "test_dataset = HitGraphDataset(input_dir=test_dir1, n_samples=test_samples, n_input_dir=2, input_dir2=test_dir2, n_samples2=test_samples)\n",
    "test_batch_sampler = JetsBatchSampler(test_dataset.n_hits, batch_size)\n",
    "collate_fn = Batch.from_data_list\n",
    "test_data_loader = DataLoader(test_dataset, batch_sampler=test_batch_sampler, collate_fn=collate_fn)\n",
    "print('Loaded %g inference samples' % len(test_data_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'prec': 0.6993868064484225, 'recall': 0.70715, 'acc': 0.7016, 'F1': 0.7032469792650788}\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda'\n",
    "model.to(DEVICE)\n",
    "# model_track.to(DEVICE)\n",
    "test_loss = 0\n",
    "\n",
    "preds = []\n",
    "labels = []\n",
    "event_labels = []\n",
    "count = 0\n",
    "for batch in test_data_loader:\n",
    "    count += 1\n",
    "    batch_size = batch.batch[-1]+1\n",
    "    hits = batch.x#hits_info. : (N1+ N2 + ...)*input_features \n",
    "    edge_index = batch.edge_index #GNN-edge\n",
    "    e = batch.e\n",
    "    trig = batch.trigger #trigger or not, 0 for NN, 1 for trigger, 2 for ND\n",
    "    event_labels.append(trig.long())\n",
    "    trig = (trig == 1)\n",
    "    trig = trig.to(DEVICE, torch.float)\n",
    "    labels.append(trig.long().cpu().numpy())\n",
    "    \n",
    "\n",
    "    # One Train step on the current batch\n",
    "    hits = hits.to(DEVICE, torch.float)\n",
    "    edge_index = edge_index.to(DEVICE, torch.long)\n",
    "    e = e.to(DEVICE, torch.float)\n",
    "    batch.batch = batch.batch.to(DEVICE, torch.long)\n",
    "\n",
    "\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        ip_pred = model(hits, edge_index, batch.batch, batch_size, e)\n",
    "        ip_pred = ip_pred.squeeze(1)\n",
    "        # ip_pred_track = ip_pred_track.squeeze(1)\n",
    "        preds.append((ip_pred).cpu().data.numpy())     \n",
    "        loss = model.get_loss(ip_pred, trig)\n",
    "    test_loss += loss.item() * batch_size\n",
    "\n",
    "\n",
    "labels = np.hstack(labels)\n",
    "preds = np.hstack(preds)\n",
    "event_labels = np.hstack(event_labels)\n",
    "result = {'prec': metrics.precision_score(labels, preds>0),\n",
    "            'recall': metrics.recall_score(labels, preds>0),\n",
    "            'acc': metrics.accuracy_score(labels, preds>0),\n",
    "            'F1': metrics.f1_score(labels, preds>0)}\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Diffpool(\n",
       "  (input_network): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=60, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (loss_func): BCELoss()\n",
       "  (ip_pred_diffpool): SoftPoolingGcnEncoder(\n",
       "    (conv_first): GraphConv()\n",
       "    (conv_block): ModuleList()\n",
       "    (conv_last): GraphConv()\n",
       "    (act): Tanh()\n",
       "    (pred_model): Sequential(\n",
       "      (0): Linear(in_features=48, out_features=50, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=50, out_features=1, bias=True)\n",
       "    )\n",
       "    (conv_first_after_pool): ModuleList(\n",
       "      (0): GraphConv()\n",
       "      (1): GraphConv()\n",
       "    )\n",
       "    (conv_block_after_pool): ModuleList(\n",
       "      (0): ModuleList()\n",
       "      (1): ModuleList()\n",
       "    )\n",
       "    (conv_last_after_pool): ModuleList(\n",
       "      (0): GraphConv()\n",
       "      (1): GraphConv()\n",
       "    )\n",
       "    (assign_conv_first_modules): ModuleList(\n",
       "      (0): GraphConv()\n",
       "      (1): GraphConv()\n",
       "    )\n",
       "    (assign_conv_block_modules): ModuleList(\n",
       "      (0): ModuleList()\n",
       "      (1): ModuleList()\n",
       "    )\n",
       "    (assign_conv_last_modules): ModuleList(\n",
       "      (0): GraphConv()\n",
       "      (1): GraphConv()\n",
       "    )\n",
       "    (assign_pred_modules): ModuleList(\n",
       "      (0): Linear(in_features=33, out_features=25, bias=True)\n",
       "      (1): Linear(in_features=14, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}